(window.webpackJsonp=window.webpackJsonp||[]).push([[4],{143:function(e,t,a){"use strict";a.r(t);var n=a(0),i=a.n(n),r=a(185),o=a(155);t.default=function(){return i.a.createElement(r.a,null,i.a.createElement(o.a,{title:"404: Not found"}),i.a.createElement("h1",null,"NOT FOUND"),i.a.createElement("p",null,"You just hit a route that doesn't exist... the sadness."))}},154:function(e,t,a){var n;e.exports=(n=a(161))&&n.default||n},155:function(e,t,a){"use strict";var n=a(156),i=a(0),r=a.n(i),o=a(4),c=a.n(o),s=a(162),u=a.n(s);function d(e){var t=e.description,a=e.lang,i=e.meta,o=e.keywords,c=e.title,s=n.data.site,d=t||s.siteMetadata.description;return r.a.createElement(u.a,{htmlAttributes:{lang:a},title:c,titleTemplate:"%s | "+s.siteMetadata.title,meta:[{name:"description",content:d},{property:"og:title",content:c},{property:"og:description",content:d},{property:"og:type",content:"website"},{name:"twitter:card",content:"summary"},{name:"twitter:creator",content:s.siteMetadata.author},{name:"twitter:title",content:c},{name:"twitter:description",content:d},{name:"google-site-verification",content:s.siteMetadata.googleSiteVerification}].concat(o.length>0?{name:"keywords",content:o.join(", ")}:[]).concat(i)})}d.defaultProps={lang:"en",meta:[],keywords:[],description:""},d.propTypes={description:c.a.string,lang:c.a.string,meta:c.a.arrayOf(c.a.object),keywords:c.a.arrayOf(c.a.string),title:c.a.string.isRequired},t.a=d},156:function(e){e.exports={data:{site:{siteMetadata:{title:"AudioCaps: Generating Captions for Audios in the Wild",description:"We explore the problem of audio captioning: generating natural language description for any kind of audio in the wild.We contribute a large-scale dataset of about 46K audio clips to human-written text pairs collected via crowdsourcing on the  AudioSet dataset.We show that our collected captions are indeed faithful for audio inputs and discover what forms of audio representation and captioning models are effective for the audio captioning.",author:"Chris Dongjoo Kim, Byeongchang Kim, Hyunmin Lee, and Gunhee Kim NAACL-HLT 2019",googleSiteVerification:"OX-dETuxFnfiO3K7Ew91HiAVqFIcBHwap-LAyvPyHOI"}}}}},157:function(e,t,a){"use strict";a.d(t,"b",function(){return d});var n=a(0),i=a.n(n),r=a(4),o=a.n(r),c=a(33),s=a.n(c);a.d(t,"a",function(){return s.a});a(154);var u=i.a.createContext({}),d=function(e){return i.a.createElement(u.Consumer,null,function(t){return e.data||t[e.query]&&t[e.query].data?(e.render||e.children)(e.data?e.data.data:t[e.query].data):i.a.createElement("div",null,"Loading (StaticQuery)")})};d.propTypes={data:o.a.object,query:o.a.string.isRequired,render:o.a.func,children:o.a.func}},160:function(e){e.exports={data:{site:{siteMetadata:{title:"AudioCaps: Generating Captions for Audios in the Wild"}}}}},161:function(e,t,a){"use strict";a.r(t);a(34);var n=a(0),i=a.n(n),r=a(4),o=a.n(r),c=a(58),s=a(2),u=function(e){var t=e.location,a=s.default.getResourcesForPathnameSync(t.pathname);return i.a.createElement(c.a,Object.assign({location:t,pageResources:a},a.json))};u.propTypes={location:o.a.shape({pathname:o.a.string.isRequired}).isRequired},t.default=u},185:function(e,t,a){"use strict";var n=a(160),i=a(0),r=a.n(i),o=a(4),c=a.n(o),s=(a(187),function(e){var t=e.children;return r.a.createElement("section",{id:"footer"},t)}),u=a(157),d=function(e){var t=e.children;return r.a.createElement(u.b,{query:"755544856",render:function(e){return r.a.createElement(r.a.Fragment,null,r.a.createElement("div",{style:{margin:"0 auto",maxWidth:960,padding:"0px 1.0875rem 1.45rem",paddingTop:0}},r.a.createElement("main",null,t)),r.a.createElement(s,null,"Copyright © AudioCaps authors  |  ",r.a.createElement("span",null,"Last update at 2019.04.16")))},data:n})};d.propTypes={children:c.a.node.isRequired};t.a=d}}]);
//# sourceMappingURL=component---src-pages-404-js-229440064e3fe208e14b.js.map